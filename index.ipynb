{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactions - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, you'll explore interactions in the Boston Housing data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will be able to:\n",
    "- Understand what interactions are\n",
    "- Understand how to accommodate for interactions in regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a baseline model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll use a couple of built-in functions, which we imported for you below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the Boston data set using `load_boston()`. We won't bother to preprocess the data in this lab. If you still want to build a model in the end, you can do that, but this lab will just focus on finding meaningful insights in interactions and how they can improve $R^2$ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression = LinearRegression()\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a baseline model which includes all the variables in the Boston housing data set to predict the house prices. The use 10-fold cross-validation and report the mean $R^2$ value as the baseline $R^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here\n",
    "X = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "y = pd.DataFrame(boston['target'], columns = ['target'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7190106820189477"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crossvalidation = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "baseline = np.mean(cross_val_score(regression, X, y, scoring=\"r2\", cv=crossvalidation))\n",
    "baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See how interactions improve your baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create all possible combinations of interactions, loop over them and add them to the baseline model one by one to see how they affect the R^2. We'll look at the 3 interactions which have the biggest effect on our R^2, so print out the top 3 combinations.\n",
    "\n",
    "You will create a for loop to loop through all the combinations of 2 predictors. You can use `combinations` from itertools to create a list of all the pairwise combinations. To find more info on how this is done, have a look [here](https://docs.python.org/2/library/itertools.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "combinations = list(combinations(boston.feature_names, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['CRIM', 'CHAS', 0.7206269810917529], ['CRIM', 'NOX', 0.7231932906349445], ['INDUS', 'RM', 0.7410809576125477], ['INDUS', 'AGE', 0.7422544294490435], ['INDUS', 'DIS', 0.7336860389690207], ['INDUS', 'RAD', 0.7320982258200397], ['INDUS', 'TAX', 0.7308692235208722], ['INDUS', 'PTRATIO', 0.7275916158581257], ['INDUS', 'B', 0.7250689042094528], ['INDUS', 'LSTAT', 0.7649420685260274], ['CHAS', 'NOX', 0.7850599420939763], ['CHAS', 'RM', 0.7740393956221318], ['CHAS', 'AGE', 0.773807018281157], ['CHAS', 'DIS', 0.7731782294538725], ['CHAS', 'RAD', 0.7650151993439086], ['CHAS', 'TAX', 0.7650225764022569], ['CHAS', 'PTRATIO', 0.7545582508202731], ['CHAS', 'B', 0.7487094300054279], ['CHAS', 'LSTAT', 0.7431809560382312], ['NOX', 'RM', 0.743123843597707], ['NOX', 'AGE', 0.741295590479375], ['NOX', 'DIS', 0.738507328402956], ['NOX', 'RAD', 0.7336781111054987], ['NOX', 'TAX', 0.7330558780845822], ['NOX', 'PTRATIO', 0.7376683692434485], ['NOX', 'B', 0.7391719467968466], ['NOX', 'LSTAT', 0.7366769218091637], ['RM', 'AGE', 0.7347405046308039], ['RM', 'DIS', 0.7326224704174016], ['RM', 'RAD', 0.760960608454798], ['RM', 'TAX', 0.7737077723266964], ['RM', 'PTRATIO', 0.7911642717056971], ['RM', 'B', 0.7913434661112464], ['RM', 'LSTAT', 0.8012435458684802], ['AGE', 'DIS', 0.8010942226513498], ['AGE', 'RAD', 0.802927689898523], ['AGE', 'TAX', 0.8031124104067864], ['AGE', 'PTRATIO', 0.8020042534550853], ['AGE', 'B', 0.8064553614229165], ['AGE', 'LSTAT', 0.8081403452757387], ['DIS', 'RAD', 0.805711609377342], ['DIS', 'TAX', 0.805634085643311], ['DIS', 'PTRATIO', 0.8076795061638082], ['DIS', 'B', 0.8066846772932907], ['DIS', 'LSTAT', 0.8222271751201538], ['RAD', 'TAX', 0.8217465349577685], ['RAD', 'PTRATIO', 0.8212044382274793], ['RAD', 'B', 0.8220543782167221], ['RAD', 'LSTAT', 0.8484406466229377], ['TAX', 'PTRATIO', 0.8532317331727193], ['TAX', 'B', 0.8531244563985616], ['TAX', 'LSTAT', 0.8528562547502243], ['PTRATIO', 'B', 0.8517475571031813], ['PTRATIO', 'LSTAT', 0.8498315273387422], ['B', 'LSTAT', 0.8460386016009632]]\n"
     ]
    }
   ],
   "source": [
    "## code to find top 3 interactions by R^2 value here\n",
    "R2 = []\n",
    "X_interact = X.copy()\n",
    "for comb in combinations:\n",
    "    X_interact['interaction'] = X_interact[comb[0]] * X_interact[comb[1]]\n",
    "    interact_R2 = np.mean(cross_val_score(regression, X_interact, y, scoring=\"r2\", cv=crossvalidation))\n",
    "    if interact_R2 > baseline:\n",
    "        R2.append([comb[0], comb[1], interact_R2])\n",
    "print(R2)\n",
    "\n",
    "data = X.copy()\n",
    "for comb in combinations:\n",
    "    data[\"interaction\"] = data[comb[0]] * data[comb[1]]\n",
    "    score = np.mean(cross_val_score(regression, data, y, scoring=\"r2\", cv=crossvalidation))\n",
    "    if score > baseline: interactions.append((comb[0], comb[1], round(score,3)))\n",
    "print(interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('TAX', 'PTRATIO')\n",
      "('TAX', 'B')\n",
      "('TAX', 'LSTAT')\n"
     ]
    }
   ],
   "source": [
    "R_list = []\n",
    "for i in range(len(R2)):\n",
    "    R_list.append(R2[i][1])\n",
    "R_list = sorted(R_list, reverse = True)\n",
    "top_3 = R_list[:3]\n",
    "for i in range(len(R2)):\n",
    "    for item in top_3:\n",
    "        if R2[i][1] == item:\n",
    "            print(R2[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('CRIM', 'CHAS', 0.722), ('CRIM', 'NOX', 0.721), ('CRIM', 'RAD', 0.722), ('CRIM', 'TAX', 0.721), ('CRIM', 'PTRATIO', 0.72), ('CRIM', 'LSTAT', 0.72), ('ZN', 'INDUS', 0.725), ('ZN', 'RM', 0.729), ('ZN', 'DIS', 0.72), ('INDUS', 'RM', 0.758), ('INDUS', 'AGE', 0.722), ('INDUS', 'DIS', 0.728), ('INDUS', 'TAX', 0.722), ('INDUS', 'LSTAT', 0.719), ('CHAS', 'RAD', 0.72), ('CHAS', 'TAX', 0.72), ('CHAS', 'B', 0.72), ('CHAS', 'LSTAT', 0.721), ('NOX', 'RM', 0.745), ('NOX', 'DIS', 0.72), ('NOX', 'RAD', 0.722), ('NOX', 'TAX', 0.719), ('NOX', 'PTRATIO', 0.721), ('NOX', 'B', 0.719), ('RM', 'AGE', 0.741), ('RM', 'DIS', 0.734), ('RM', 'RAD', 0.768), ('RM', 'TAX', 0.775), ('RM', 'PTRATIO', 0.763), ('RM', 'B', 0.739), ('RM', 'LSTAT', 0.786), ('AGE', 'DIS', 0.721), ('AGE', 'PTRATIO', 0.72), ('AGE', 'B', 0.721), ('DIS', 'PTRATIO', 0.721), ('DIS', 'B', 0.719), ('TAX', 'PTRATIO', 0.722)]\n"
     ]
    }
   ],
   "source": [
    "interactions = []\n",
    "data = X.copy()\n",
    "for comb in combinations:\n",
    "    data[\"interaction\"] = data[comb[0]] * data[comb[1]]\n",
    "    score = np.mean(cross_val_score(regression, data, y, scoring=\"r2\", cv=crossvalidation))\n",
    "    if score > baseline: interactions.append((comb[0], comb[1], round(score,3)))\n",
    "print(interactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the top 3 interactions: \"RM\" as a confounding factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top three interactions seem to involve \"RM\", the number of rooms as a confounding variable for all of them. Let's have a look at interaction plots for all three of them. This exercise will involve:\n",
    "\n",
    "- splitting our data up in 3 groups: one for houses with a few rooms, one for houses with a \"medium\" amount of rooms, one for a high amount of rooms.\n",
    "- Create a function `build_interaction_rm`. This function takes an argument `varname` (which can be set equal to the column name as a string) and a column `description` (which describes the variable or varname, to be included on the x-axis of the plot). The function outputs a plot that uses \"RM\" as a confounding factor. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data set for high, medium and low amount of rooms for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm = np.asarray(df[[\"RM\"]]).reshape(len(df[[\"RM\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_rm = all_data[rm > np.percentile(rm, 67)]\n",
    "med_rm = all_data[(rm > np.percentile(rm, 33)) & (rm <= np.percentile(rm, 67))]\n",
    "low_rm = all_data[rm <= np.percentile(rm, 33)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `build_interaction_rm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_interaction_rm(varname, description):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, use build_interaction_rm with the three variables that came out with the highest effect on $R^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# third plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a final model including all three interactions at once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use 10-fold crossvalidation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our $R^2$ has increased considerably! Let's have a look in statsmodels to see if all these interactions are significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is your conclusion here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# formulate your conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now understand how to include interaction effects in your model!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
